{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b7a738f-2295-4c52-8f4d-ed6f66456b34",
   "metadata": {},
   "source": [
    "# üé≠ AI-Powered Themed Star Schema Generator\n",
    "\n",
    "Generate synthetic analytical datasets with Azure OpenAI and Spark.\n",
    "\n",
    "**Features:**\n",
    "- ü§ñ GPT-4 generates creative themed content\n",
    "- ‚ö° Spark builds fact tables efficiently\n",
    "- üîê Secure Key Vault credential management\n",
    "- üì¶ Fallback to preloaded themes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd6123d-3df2-421d-a66b-e7b0ca4f371e",
   "metadata": {},
   "source": [
    "## üéØ Step 1: Configuration\n",
    "\n",
    "**Set your demo parameters here!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138c279-86f4-4741-b58a-ad320fb954a0",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-15T22:29:34.5225979Z",
       "execution_start_time": "2025-11-15T22:29:34.1293632Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "dee38c48-0f2c-45c8-8dd2-546e29b886c9",
       "queued_time": "2025-11-15T22:29:20.3475992Z",
       "session_id": "e3fa5b02-20b6-4b8f-a663-589c44bbfbe0",
       "session_start_time": "2025-11-15T22:29:20.3485805Z",
       "spark_pool": null,
       "state": "finished",
       "statement_id": 3,
       "statement_ids": [
        3
       ]
      },
      "text/plain": [
       "StatementMeta(, e3fa5b02-20b6-4b8f-a663-589c44bbfbe0, 3, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Generating MEDIUM Roadkill Restaurant Dataset\n",
      "üóÑÔ∏è  Lakehouse: Default\n",
      "ü§ñ Mode: AI\n",
      "üîë Credentials: Direct (from configuration)\n",
      "üé≤ Seed: 42\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Lakehouse Configuration\n",
    "lakehouse_name = \"\"  # Leave blank for default\n",
    "\n",
    "# Business Type: \"Retail\", \"Restaurant\", \"Healthcare\"\n",
    "business_type = \"Restaurant\"\n",
    "\n",
    "# Theme: \"Gourmet Fantasy Food\", \"Space Colony\", etc.\n",
    "theme = \"Roadkill\"\n",
    "\n",
    "# Generation Mode: \"AI\" (use Azure OpenAI) or \"Preloaded\" (no API needed)\n",
    "generation_mode = \"AI\"\n",
    "\n",
    "# Credential Source: \"direct\" \n",
    "credential_source = \"direct\"\n",
    "\n",
    "# Direct credentials - if you  use a direct key like this - regenerate it right away after a demo!\n",
    "direct_endpoint = \"Your open ai endpoint\"\n",
    "direct_key = \"Your openai key\"  \n",
    "direct_deployment = \"gpt4o-demo\"\n",
    "\n",
    "# Data Settings\n",
    "random_seed = 42\n",
    "record_scale = \"medium\"  # \"small\" (10K), \"medium\" (25K), \"large\" (500K)\n",
    "\n",
    "print(f\"üé¨ Generating {record_scale.upper()} {theme} {business_type} Dataset\")\n",
    "print(f\"üóÑÔ∏è  Lakehouse: {lakehouse_name if lakehouse_name else 'Default'}\")\n",
    "print(f\"ü§ñ Mode: {generation_mode}\")\n",
    "if generation_mode == \"AI\":\n",
    "    print(f\"üîë Credentials: Direct (from configuration)\")\n",
    "print(f\"üé≤ Seed: {random_seed}\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e525322d-08e4-4d48-928c-83bcc80ca1e9",
   "metadata": {},
   "source": [
    "## üìö Step 2: Import Libraries & Setup Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e85d753-42ad-41a7-afac-3d2a0851f5af",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-15T22:30:43.3315317Z",
       "execution_start_time": "2025-11-15T22:30:42.4493666Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "90e1413a-867b-4c94-8b0e-0bd7e0c39a47",
       "queued_time": "2025-11-15T22:30:42.4481501Z",
       "session_id": "e3fa5b02-20b6-4b8f-a663-589c44bbfbe0",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 4,
       "statement_ids": [
        4
       ]
      },
      "text/plain": [
       "StatementMeta(, e3fa5b02-20b6-4b8f-a663-589c44bbfbe0, 4, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóÑÔ∏è  Using default lakehouse\n",
      "‚úÖ Spark initialized (v3.5.5.5.4.20251103.2)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Set random seeds\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Initialize Spark\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"8\")\n",
    "\n",
    "# Set lakehouse context\n",
    "if lakehouse_name:\n",
    "    print(f\"üóÑÔ∏è  Using lakehouse: {lakehouse_name}\")\n",
    "    spark.sql(f\"USE {lakehouse_name}\")\n",
    "else:\n",
    "    print(\"üóÑÔ∏è  Using default lakehouse\")\n",
    "\n",
    "print(f\"‚úÖ Spark initialized (v{spark.version})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b4f7a1-fd9c-4b8e-9def-2e0cd1803cb2",
   "metadata": {},
   "source": [
    "## üîê Step 3: Load Credentials from Key Vault\n",
    "\n",
    "**This securely loads your Azure OpenAI credentials.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cc477c9-8f41-4b50-8b6b-5a5cebf08ffb",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-15T22:32:00.2980156Z",
       "execution_start_time": "2025-11-15T22:31:59.9314423Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "5a3d27e1-f8b1-4974-ac16-5e4cc8128703",
       "queued_time": "2025-11-15T22:31:59.9303976Z",
       "session_id": "e3fa5b02-20b6-4b8f-a663-589c44bbfbe0",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 6,
       "statement_ids": [
        6
       ]
      },
      "text/plain": [
       "StatementMeta(, e3fa5b02-20b6-4b8f-a663-589c44bbfbe0, 6, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë Loading direct credentials\n",
      "\n",
      "‚úÖ Credentials loaded successfully!\n",
      "   Endpoint: https://pmcai-openai.openai.azure.com/\n",
      "   Deployment: gpt4o-demo\n",
      "   Key: ******************** (hidden)\n",
      "\n",
      "üîç Debug Info:\n",
      "   Key length: 84\n",
      "   Key starts with: 2ilMR...\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "azure_openai_endpoint = None\n",
    "azure_openai_key = None\n",
    "azure_openai_deployment = None\n",
    "\n",
    "if generation_mode == \"AI\":\n",
    "    if credential_source == \"direct\":\n",
    "        print(\"üîë Loading direct credentials\\n\")\n",
    "        \n",
    "        azure_openai_endpoint = direct_endpoint\n",
    "        azure_openai_key = direct_key\n",
    "        azure_openai_deployment = direct_deployment\n",
    "        \n",
    "        print(\"‚úÖ Credentials loaded successfully!\")\n",
    "        print(f\"   Endpoint: {azure_openai_endpoint}\")\n",
    "        print(f\"   Deployment: {azure_openai_deployment}\")\n",
    "        print(f\"   Key: {'*' * 20} (hidden)\")\n",
    "        \n",
    "        # Debug info\n",
    "        print(f\"\\nüîç Debug Info:\")\n",
    "        print(f\"   Key length: {len(azure_openai_key)}\")\n",
    "        print(f\"   Key starts with: {azure_openai_key[:5]}...\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Key Vault not configured for this environment\")\n",
    "        print(\"üì¶ Falling back to Preloaded mode...\")\n",
    "        generation_mode = \"Preloaded\"\n",
    "else:\n",
    "    print(\"üì¶ Using Preloaded mode - no credentials needed\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc394a-6a0c-495b-82bf-c0e789fe060c",
   "metadata": {},
   "source": [
    "## ü§ñ Step 4: AI Theme Generation\n",
    "\n",
    "**Azure OpenAI generates creative themed content, or we use preloaded themes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32efa4b8-9a08-4bb2-93b2-d6cdbff80464",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-15T22:34:08.8903386Z",
       "execution_start_time": "2025-11-15T22:34:04.0514388Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "7aa7aaa1-0454-4b3d-8f7a-01cc136a93d2",
       "queued_time": "2025-11-15T22:34:04.049789Z",
       "session_id": "e3fa5b02-20b6-4b8f-a663-589c44bbfbe0",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 7,
       "statement_ids": [
        7
       ]
      },
      "text/plain": [
       "StatementMeta(, e3fa5b02-20b6-4b8f-a663-589c44bbfbe0, 7, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ü§ñ Asking Azure OpenAI to generate Roadkill content...\n",
      "\n",
      "   Trying API version: 2024-08-01-preview...\n",
      "\n",
      "‚úÖ Azure OpenAI generated creative content!\n",
      "   Sample products: ['Armadillo Appetizer', 'Possum Pie', 'Raccoon Ribs']\n",
      "   Sample brands: ['Treaded Treats', 'Pavement Platters']\n",
      "\n",
      "‚úÖ Themed content ready!\n",
      "   Products: 20\n",
      "   Categories: 8\n",
      "   Locations: 10\n",
      "   Brands: 8\n"
     ]
    }
   ],
   "source": [
    "def generate_themed_content_with_azure_openai(business_type, theme):\n",
    "    \"\"\"Use Azure OpenAI to generate creative themed content.\"\"\"\n",
    "    print(f\"ü§ñ Asking Azure OpenAI to generate {theme} content...\\n\")\n",
    "    \n",
    "    if not all([azure_openai_endpoint, azure_openai_key, azure_openai_deployment]):\n",
    "        print(\"‚ö†Ô∏è  Credentials not available\")\n",
    "        return None\n",
    "    \n",
    "    # Determine terminology\n",
    "    if business_type == \"Restaurant\":\n",
    "        product_term = \"menu items\"\n",
    "        service_term = \"dining services\"\n",
    "    elif business_type == \"Healthcare\":\n",
    "        product_term = \"medical procedures and treatments\"\n",
    "        service_term = \"medical services\"\n",
    "    else:\n",
    "        product_term = \"products\"\n",
    "        service_term = \"customer services\"\n",
    "    \n",
    "    prompt = f\"\"\"Generate creative, themed content for a {business_type} business with a {theme} theme.\n",
    "\n",
    "Create these lists with UNIQUE, CREATIVE names:\n",
    "1. product_names: 20 {product_term}\n",
    "2. categories: 8 categories\n",
    "3. brands: 8 brand names\n",
    "4. locations: 10 location names\n",
    "5. services: 6 {service_term}\n",
    "6. adjectives: 8 descriptive adjectives\n",
    "7. first_names: 12 character first names\n",
    "8. last_names: 10 character last names\n",
    "\n",
    "Respond ONLY with valid JSON (no markdown, no explanation):\n",
    "{{\n",
    "  \"product_names\": [\"name1\", \"name2\", ...],\n",
    "  \"categories\": [...],\n",
    "  \"brands\": [...],\n",
    "  \"locations\": [...],\n",
    "  \"services\": [...],\n",
    "  \"adjectives\": [...],\n",
    "  \"first_names\": [...],\n",
    "  \"last_names\": [...]\n",
    "}}\"\"\"\n",
    "    \n",
    "    try:\n",
    "        import requests\n",
    "        \n",
    "        # Try multiple API versions for compatibility\n",
    "        api_versions = [\"2024-08-01-preview\", \"2024-06-01\", \"2024-02-15-preview\"]\n",
    "        \n",
    "        for api_version in api_versions:\n",
    "            url = f\"{azure_openai_endpoint}openai/deployments/{azure_openai_deployment}/chat/completions?api-version={api_version}\"\n",
    "            \n",
    "            headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"api-key\": azure_openai_key\n",
    "            }\n",
    "            \n",
    "            data = {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"You generate creative themed content for data demos. Always respond with valid JSON only.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                \"temperature\": 0.8,\n",
    "                \"max_tokens\": 2000\n",
    "            }\n",
    "            \n",
    "            print(f\"   Trying API version: {api_version}...\")\n",
    "            response = requests.post(url, headers=headers, json=data, timeout=30)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                content = response.json()['choices'][0]['message']['content']\n",
    "                content = content.replace('```json', '').replace('```', '').strip()\n",
    "                themed_content = json.loads(content)\n",
    "                \n",
    "                print(\"\\n‚úÖ Azure OpenAI generated creative content!\")\n",
    "                print(f\"   Sample products: {themed_content['product_names'][:3]}\")\n",
    "                print(f\"   Sample brands: {themed_content['brands'][:2]}\")\n",
    "                \n",
    "                return themed_content\n",
    "            elif response.status_code == 401:\n",
    "                print(f\"   ‚ùå 401 Authentication failed\")\n",
    "                print(f\"   Message: {response.text[:200]}\")\n",
    "                break  # Don't try other API versions for auth errors\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è  {response.status_code} - trying next version...\")\n",
    "        \n",
    "        print(f\"\\n‚ùå All API versions failed\")\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_preloaded_content(theme):\n",
    "    \"\"\"Fallback: Use pre-generated content.\"\"\"\n",
    "    preloaded_data = {\n",
    "        \"Gourmet Fantasy Food\": {\n",
    "            \"product_names\": [\"Dragon's Breath Soup\", \"Moonlit Truffle Risotto\", \"Phoenix Flame Steak\", \n",
    "                             \"Elvish Honey Cake\", \"Wizard's Whiskey Glaze\", \"Unicorn Tears Sorbet\",\n",
    "                             \"Mermaid's Pearl Pasta\", \"Griffin Wing Roast\", \"Enchanted Forest Salad\",\n",
    "                             \"Fairy Dust Souffl√©\", \"Troll's Mushroom Medley\", \"Celestial Berry Tart\",\n",
    "                             \"Kraken Ink Risotto\", \"Starlight Nectar\", \"Moon-Baked Tart\",\n",
    "                             \"Goblin's Gold Curry\", \"Siren Song Seafood\", \"Pegasus Pear Tart\", \"Basilisk Bite\", \"Chimera Chowder\"],\n",
    "            \"categories\": [\"Mystical Appetizers\", \"Legendary Entrees\", \"Enchanted Desserts\", \n",
    "                          \"Magical Beverages\", \"Fantasy Sides\", \"Divine Soups\", \"Ethereal Salads\", \"Mythical Mains\"],\n",
    "            \"brands\": [\"Ivory Tower Cuisine\", \"Mystic Pantry\", \"Enchanted Eats\", \"Arcane Flavors\", \n",
    "                      \"Celestial Kitchen\", \"Wizard's Table\", \"Dragon's Feast\", \"Elven Delights\"],\n",
    "            \"locations\": [\"Castle Keep\", \"Mystic Grove\", \"Enchanted Garden\", \"Crystal Palace\", \n",
    "                         \"Dragon's Lair\", \"Fairy Circle\", \"Wizard's Tower\", \"Moonlight Pavilion\", \"Starfall Inn\", \"Phoenix Nest\"],\n",
    "            \"services\": [\"Potion Pairing\", \"Spell-Infused Cooking\", \"Mystical Wine Selection\", \"Enchantment Experience\", \"Magic Tasting Menu\", \"Alchemical Desserts\"],\n",
    "            \"adjectives\": [\"Enchanted\", \"Mystical\", \"Legendary\", \"Ethereal\", \"Bewitched\", \"Arcane\", \"Celestial\", \"Divine\"],\n",
    "            \"first_names\": [\"Merlin\", \"Galadriel\", \"Aragorn\", \"Luna\", \"Oberon\", \"Titania\", \"Elric\", \"Morgana\", \"Theron\", \"Selene\", \"Orion\", \"Aurora\"],\n",
    "            \"last_names\": [\"Starweaver\", \"Moonwhisper\", \"Dragonheart\", \"Spellbinder\", \"Frostborne\", \"Shadowmere\", \"Nightshade\", \"Stormcaller\", \"Brightflame\", \"Silverwind\"]\n",
    "        },\n",
    "        \"Space Colony\": {\n",
    "            \"product_names\": [\"Nebula Nutrient Pack\", \"Asteroid Mining Gear\", \"Gravity Stabilizer\", \"Oxygen Recycler Pro\",\n",
    "                             \"Plasma Shield Generator\", \"Hyperdrive Fuel Cell\", \"Zero-G Coffee Maker\", \"Mars Habitat Module\",\n",
    "                             \"Stellar Navigation Kit\", \"Cosmic Radiation Suit\", \"Ion Propulsion Unit\", \"Terraform Toolkit\",\n",
    "                             \"Quantum Communicator\", \"Solar Panel Array\", \"Cryosleep Pod\", \"Antimatter Reactor\",\n",
    "                             \"Meteor Defense System\", \"Lunar Rover Kit\", \"Warp Core\", \"Space Station Hub\"],\n",
    "            \"categories\": [\"Life Support\", \"Mining Equipment\", \"Habitation\", \"Transportation\", \"Communication\", \"Power Systems\", \"Safety Gear\", \"Colony Infrastructure\"],\n",
    "            \"brands\": [\"StellarTech\", \"GalaxyCorp\", \"NebulaWorks\", \"CosmicSolutions\", \"OrbitTech\", \"VoidIndustries\", \"AstroSystems\", \"Quantum Dynamics\"],\n",
    "            \"locations\": [\"Mars Station Alpha\", \"Lunar Base Prime\", \"Asteroid Belt Outpost\", \"Jupiter Transit Hub\",\n",
    "                         \"Saturn Ring Station\", \"Titan Colony\", \"Orbital Platform 7\", \"Europa Research Base\", \"Io Mining Station\", \"Ganymede Port\"],\n",
    "            \"services\": [\"Gravity Adjustment\", \"Atmosphere Calibration\", \"Radiation Shielding\", \"Hypersleep Monitoring\", \"Terraforming Consultation\", \"Space Walk Training\"],\n",
    "            \"adjectives\": [\"Advanced\", \"Cosmic\", \"Interstellar\", \"Zero-Gravity\", \"Quantum\", \"Galactic\", \"Stellar\", \"Orbital\"],\n",
    "            \"first_names\": [\"Nova\", \"Orion\", \"Stella\", \"Cosmo\", \"Astrid\", \"Apollo\", \"Luna\", \"Atlas\", \"Vega\", \"Sirius\", \"Andromeda\", \"Phoenix\"],\n",
    "            \"last_names\": [\"Stardust\", \"Nebula\", \"Cosmos\", \"Skywalker\", \"Astral\", \"Galaxy\", \"Void\", \"Quasar\", \"Comet\", \"Pulsar\"]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return preloaded_data.get(theme, preloaded_data[\"Gourmet Fantasy Food\"])\n",
    "\n",
    "\n",
    "# Generate themed content\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "if generation_mode == \"AI\":\n",
    "    theme_data = generate_themed_content_with_azure_openai(business_type, theme)\n",
    "    if theme_data is None:\n",
    "        print(\"\\nüì¶ Falling back to preloaded content...\")\n",
    "        theme_data = get_preloaded_content(theme)\n",
    "else:\n",
    "    print(\"üì¶ Using preloaded themed content\")\n",
    "    theme_data = get_preloaded_content(theme)\n",
    "\n",
    "theme_first_names = theme_data['first_names']\n",
    "theme_last_names = theme_data['last_names']\n",
    "\n",
    "print(f\"\\n‚úÖ Themed content ready!\")\n",
    "print(f\"   Products: {len(theme_data['product_names'])}\")\n",
    "print(f\"   Categories: {len(theme_data['categories'])}\")\n",
    "print(f\"   Locations: {len(theme_data['locations'])}\")\n",
    "print(f\"   Brands: {len(theme_data['brands'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bab00e6-2650-4203-91d1-a57565023740",
   "metadata": {},
   "source": [
    "## üìÖ Step 5: Generate Date Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0546e74-7051-4e70-869a-686bd9ffc1ca",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-15T22:34:40.5020462Z",
       "execution_start_time": "2025-11-15T22:34:35.7150302Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "1e179368-e311-4857-a019-81901577e8d1",
       "queued_time": "2025-11-15T22:34:35.7138155Z",
       "session_id": "e3fa5b02-20b6-4b8f-a663-589c44bbfbe0",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 8,
       "statement_ids": [
        8
       ]
      },
      "text/plain": [
       "StatementMeta(, e3fa5b02-20b6-4b8f-a663-589c44bbfbe0, 8, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìÖ Generating Date Dimension...\n",
      "\n",
      "‚úÖ Date Dimension: 365 days\n",
      "   Range: 2024-11-16 to 2025-11-15\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìÖ Generating Date Dimension...\\n\")\n",
    "\n",
    "end_date = datetime.now().date()\n",
    "start_date = end_date - timedelta(days=364)\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "dim_date_pd = pd.DataFrame({\n",
    "    'date_key': range(1, len(date_range) + 1),\n",
    "    'date': date_range,\n",
    "    'year': date_range.year.astype('int32'),\n",
    "    'quarter': date_range.quarter.astype('int32'),\n",
    "    'month': date_range.month.astype('int32'),\n",
    "    'month_name': date_range.strftime('%B'),\n",
    "    'day': date_range.day.astype('int32'),\n",
    "    'day_of_week': (date_range.dayofweek + 1).astype('int32'),\n",
    "    'day_name': date_range.strftime('%A'),\n",
    "    'week_of_year': date_range.isocalendar().week.astype('int32'),\n",
    "    'is_weekend': (date_range.dayofweek >= 5).astype('int32'),\n",
    "    'is_month_start': date_range.is_month_start.astype('int32'),\n",
    "    'is_month_end': date_range.is_month_end.astype('int32'),\n",
    "    'is_quarter_start': date_range.is_quarter_start.astype('int32'),\n",
    "    'is_quarter_end': date_range.is_quarter_end.astype('int32')\n",
    "})\n",
    "\n",
    "dim_date = spark.createDataFrame(dim_date_pd)\n",
    "\n",
    "print(f\"‚úÖ Date Dimension: {dim_date.count()} days\")\n",
    "print(f\"   Range: {start_date} to {end_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a815f68a-5fd3-47e1-89ba-85d847b66405",
   "metadata": {},
   "source": [
    "## üè¢ Step 6: Generate Dimension Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a025c6b-1f2d-45b7-9137-ed3d2803001a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-15T22:35:11.3277198Z",
       "execution_start_time": "2025-11-15T22:35:10.4837892Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "216883a5-b52d-4fee-8fb0-d3617bac8287",
       "queued_time": "2025-11-15T22:35:10.4824809Z",
       "session_id": "e3fa5b02-20b6-4b8f-a663-589c44bbfbe0",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 9,
       "statement_ids": [
        9
       ]
      },
      "text/plain": [
       "StatementMeta(, e3fa5b02-20b6-4b8f-a663-589c44bbfbe0, 9, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üè¢ Generating Dimension Tables...\n",
      "\n",
      "üè∑Ô∏è  Products (700 records)...\n",
      "üìç Locations (100 Restaurants)...\n",
      "üë• Customers (800 records)...\n",
      "üëî Employees (150 records)...\n",
      "\n",
      "‚úÖ All dimensions generated!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üè¢ Generating Dimension Tables...\\n\")\n",
    "\n",
    "def generate_product_dimension(n_records=200):\n",
    "    print(f\"üè∑Ô∏è  Products ({n_records} records)...\")\n",
    "    product_pool = theme_data['product_names'] * (n_records // len(theme_data['product_names']) + 2)\n",
    "    np.random.shuffle(product_pool)\n",
    "    \n",
    "    dim_product_pd = pd.DataFrame({\n",
    "        'product_key': range(1, n_records + 1),\n",
    "        'product_name': [f\"{np.random.choice(theme_data['adjectives'])} {product_pool[i]}\" \n",
    "                        for i in range(n_records)],\n",
    "        'category': np.random.choice(theme_data['categories'], n_records),\n",
    "        'brand': np.random.choice(theme_data['brands'], n_records),\n",
    "        'unit_price': np.round(np.random.uniform(5, 500, n_records), 2),\n",
    "        'unit_cost': np.round(np.random.uniform(2, 250, n_records), 2),\n",
    "        'is_active': np.random.choice([1, 1, 1, 0], n_records)\n",
    "    })\n",
    "    dim_product_pd['unit_cost'] = np.minimum(dim_product_pd['unit_cost'], \n",
    "                                              dim_product_pd['unit_price'] * 0.7)\n",
    "    return spark.createDataFrame(dim_product_pd)\n",
    "\n",
    "def generate_location_dimension(n_records=100):\n",
    "    loc_name = {\"Retail\": \"Store\", \"Restaurant\": \"Restaurant\", \"Healthcare\": \"Facility\"}[business_type]\n",
    "    print(f\"üìç Locations ({n_records} {loc_name}s)...\")\n",
    "    location_pool = theme_data['locations'] * (n_records // len(theme_data['locations']) + 2)\n",
    "    np.random.shuffle(location_pool)\n",
    "    \n",
    "    dim_location_pd = pd.DataFrame({\n",
    "        'location_key': range(1, n_records + 1),\n",
    "        'location_name': [f\"{location_pool[i]} {loc_name} #{i+1}\" for i in range(n_records)],\n",
    "        'city': np.random.choice(['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix',\n",
    "                                 'Philadelphia', 'San Antonio', 'San Diego', 'Dallas', 'Austin'], n_records),\n",
    "        'state': np.random.choice(['NY', 'CA', 'IL', 'TX', 'AZ', 'PA', 'FL'], n_records),\n",
    "        'region': np.random.choice(['Northeast', 'Southeast', 'Midwest', 'Southwest', 'West'], n_records),\n",
    "        'size_sqft': np.random.randint(1000, 10000, n_records),\n",
    "        'opened_date': pd.to_datetime(\n",
    "            np.random.choice(pd.date_range('2015-01-01', '2023-12-31', freq='D'), n_records)\n",
    "        )\n",
    "    })\n",
    "    return spark.createDataFrame(dim_location_pd)\n",
    "\n",
    "def generate_customer_dimension(n_records=300):\n",
    "    entity = \"Patient\" if business_type == \"Healthcare\" else \"Customer\"\n",
    "    print(f\"üë• {entity}s ({n_records} records)...\")\n",
    "    \n",
    "    dim_customer_pd = pd.DataFrame({\n",
    "        'customer_key': range(1, n_records + 1),\n",
    "        'first_name': np.random.choice(theme_first_names, n_records),\n",
    "        'last_name': np.random.choice(theme_last_names, n_records),\n",
    "        'email_domain': np.random.choice(['gmail.com', 'yahoo.com', 'outlook.com', 'company.com'], n_records),\n",
    "        'age': np.random.randint(18, 80, n_records),\n",
    "        'gender': np.random.choice(['M', 'F', 'O'], n_records),\n",
    "        'loyalty_tier': np.random.choice(['Bronze', 'Silver', 'Gold', 'Platinum', None], n_records),\n",
    "        'join_date': pd.to_datetime(\n",
    "            np.random.choice(pd.date_range('2018-01-01', '2024-12-31', freq='D'), n_records)\n",
    "        ),\n",
    "        'lifetime_value': np.round(np.random.uniform(50, 5000, n_records), 2)\n",
    "    })\n",
    "    dim_customer_pd['email'] = (\n",
    "        dim_customer_pd['first_name'].str.lower() + '.' + \n",
    "        dim_customer_pd['last_name'].str.lower() + '@' + \n",
    "        dim_customer_pd['email_domain']\n",
    "    )\n",
    "    dim_customer_pd = dim_customer_pd.drop(columns=['email_domain'])\n",
    "    return spark.createDataFrame(dim_customer_pd)\n",
    "\n",
    "def generate_employee_dimension(n_records=150):\n",
    "    print(f\"üëî Employees ({n_records} records)...\")\n",
    "    roles = {\n",
    "        \"Healthcare\": ['Physician', 'Nurse', 'Technician', 'Specialist', 'Therapist', 'Administrator'],\n",
    "        \"Restaurant\": ['Chef', 'Server', 'Bartender', 'Host', 'Manager', 'Cook'],\n",
    "        \"Retail\": ['Sales Associate', 'Manager', 'Cashier', 'Stock Clerk', 'Supervisor']\n",
    "    }[business_type]\n",
    "    \n",
    "    dim_employee_pd = pd.DataFrame({\n",
    "        'employee_key': range(1, n_records + 1),\n",
    "        'first_name': np.random.choice(theme_first_names, n_records),\n",
    "        'last_name': np.random.choice(theme_last_names, n_records),\n",
    "        'role': np.random.choice(roles, n_records),\n",
    "        'department': np.random.choice(['Operations', 'Sales', 'Management', 'Support'], n_records),\n",
    "        'hire_date': pd.to_datetime(\n",
    "            np.random.choice(pd.date_range('2015-01-01', '2024-12-31', freq='D'), n_records)\n",
    "        ),\n",
    "        'hourly_rate': np.round(np.random.uniform(15, 75, n_records), 2),\n",
    "        'is_full_time': np.random.choice([1, 1, 0], n_records)\n",
    "    })\n",
    "    return spark.createDataFrame(dim_employee_pd)\n",
    "\n",
    "# Generate dimensions\n",
    "dim_product = generate_product_dimension(700)\n",
    "dim_location = generate_location_dimension(100)\n",
    "dim_customer = generate_customer_dimension(800)\n",
    "dim_employee = generate_employee_dimension(150)\n",
    "\n",
    "print(\"\\n‚úÖ All dimensions generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac66700b-42c5-42e1-a849-6cc764e3b474",
   "metadata": {},
   "source": [
    "## üî• Step 7: Generate Fact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7abf777c-f11c-47d9-9ad5-027171797c17",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-15T22:35:36.1337727Z",
       "execution_start_time": "2025-11-15T22:35:32.5900484Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "05a2f087-fc37-46de-8323-2b3e4e2c0b5a",
       "queued_time": "2025-11-15T22:35:32.5887217Z",
       "session_id": "e3fa5b02-20b6-4b8f-a663-589c44bbfbe0",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 10,
       "statement_ids": [
        10
       ]
      },
      "text/plain": [
       "StatementMeta(, e3fa5b02-20b6-4b8f-a663-589c44bbfbe0, 10, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üî• Generating Fact Table (25,000 rows)...\n",
      "   This takes 15-30 seconds...\n",
      "\n",
      "‚úÖ Fact table generated: 25,000 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "scale_sizes = {\"small\": 10000, \"medium\": 25000, \"large\": 50000}\n",
    "fact_row_count = scale_sizes[record_scale]\n",
    "\n",
    "print(f\"üî• Generating Fact Table ({fact_row_count:,} rows)...\")\n",
    "print(f\"   This takes 15-30 seconds...\\n\")\n",
    "\n",
    "n_products = dim_product.count()\n",
    "n_locations = dim_location.count()\n",
    "n_customers = dim_customer.count()\n",
    "n_employees = dim_employee.count()\n",
    "n_dates = dim_date.count()\n",
    "\n",
    "# Create base with foreign keys (pure Spark!)\n",
    "fact_base = spark.range(1, fact_row_count + 1).toDF(\"transaction_id\")\n",
    "fact_with_keys = fact_base \\\n",
    "    .withColumn(\"product_key\", (F.col(\"transaction_id\") * 7 + random_seed) % n_products + 1) \\\n",
    "    .withColumn(\"location_key\", (F.col(\"transaction_id\") * 11 + random_seed) % n_locations + 1) \\\n",
    "    .withColumn(\"customer_key\", (F.col(\"transaction_id\") * 13 + random_seed) % n_customers + 1) \\\n",
    "    .withColumn(\"employee_key\", (F.col(\"transaction_id\") * 17 + random_seed) % n_employees + 1) \\\n",
    "    .withColumn(\"date_key\", (F.col(\"transaction_id\") * 19 + random_seed) % n_dates + 1) \\\n",
    "    .withColumn(\"hour_of_day\", (F.col(\"transaction_id\") * 23 + random_seed) % 24) \\\n",
    "    .withColumn(\"_seed\", (F.col(\"transaction_id\") + random_seed))\n",
    "\n",
    "# Add business-specific metrics\n",
    "if business_type == \"Retail\":\n",
    "    fact_table = fact_with_keys \\\n",
    "        .withColumn(\"quantity\", (F.col(\"_seed\") % 10) + 1) \\\n",
    "        .withColumn(\"discount_percent\", F.when(F.col(\"_seed\") % 3 == 0, (F.col(\"_seed\") % 20) + 5).otherwise(0)) \\\n",
    "        .withColumn(\"is_online\", (F.col(\"_seed\") % 4 == 0).cast(\"int\")) \\\n",
    "        .withColumn(\"is_return\", (F.col(\"_seed\") % 20 == 0).cast(\"int\"))\n",
    "    fact_name = \"sales\"\n",
    "elif business_type == \"Restaurant\":\n",
    "    fact_table = fact_with_keys \\\n",
    "        .withColumn(\"quantity\", (F.col(\"_seed\") % 5) + 1) \\\n",
    "        .withColumn(\"table_number\", (F.col(\"_seed\") % 30) + 1) \\\n",
    "        .withColumn(\"party_size\", (F.col(\"_seed\") % 8) + 1) \\\n",
    "        .withColumn(\"is_takeout\", (F.col(\"_seed\") % 5 == 0).cast(\"int\")) \\\n",
    "        .withColumn(\"tip_percent\", F.when(F.col(\"is_takeout\") == 0, (F.col(\"_seed\") % 10) + 15).otherwise(0))\n",
    "    fact_name = \"orders\"\n",
    "else:  # Healthcare\n",
    "    fact_table = fact_with_keys \\\n",
    "        .withColumn(\"quantity\", F.lit(1)) \\\n",
    "        .withColumn(\"visit_type\", \n",
    "                   F.when(F.col(\"_seed\") % 4 == 0, F.lit(\"Emergency\"))\n",
    "                   .when(F.col(\"_seed\") % 4 == 1, F.lit(\"Routine\"))\n",
    "                   .when(F.col(\"_seed\") % 4 == 2, F.lit(\"Follow-up\"))\n",
    "                   .otherwise(F.lit(\"Specialist\"))) \\\n",
    "        .withColumn(\"visit_duration_minutes\", (F.col(\"_seed\") % 120) + 15) \\\n",
    "        .withColumn(\"is_insured\", (F.col(\"_seed\") % 10 != 0).cast(\"int\")) \\\n",
    "        .withColumn(\"insurance_copay\", F.when(F.col(\"is_insured\") == 1, (F.col(\"_seed\") % 50) + 10).otherwise(0))\n",
    "    fact_name = \"visits\"\n",
    "\n",
    "fact_table = fact_table.drop(\"_seed\")\n",
    "\n",
    "# Join with product for pricing\n",
    "fact_table = fact_table.join(\n",
    "    dim_product.select(\"product_key\", \"unit_price\", \"unit_cost\"),\n",
    "    on=\"product_key\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Calculate amounts\n",
    "fact_table = fact_table.withColumn(\"gross_amount\", F.col(\"quantity\") * F.col(\"unit_price\"))\n",
    "\n",
    "if business_type == \"Retail\":\n",
    "    fact_table = fact_table \\\n",
    "        .withColumn(\"discount_amount\", F.col(\"gross_amount\") * (F.col(\"discount_percent\") / 100)) \\\n",
    "        .withColumn(\"net_amount\", F.col(\"gross_amount\") - F.col(\"discount_amount\"))\n",
    "elif business_type == \"Restaurant\":\n",
    "    fact_table = fact_table \\\n",
    "        .withColumn(\"tip_amount\", F.col(\"gross_amount\") * (F.col(\"tip_percent\") / 100)) \\\n",
    "        .withColumn(\"net_amount\", F.col(\"gross_amount\") + F.col(\"tip_amount\"))\n",
    "else:\n",
    "    fact_table = fact_table \\\n",
    "        .withColumn(\"insurance_covered\", F.when(F.col(\"is_insured\") == 1, F.col(\"gross_amount\") * 0.8).otherwise(0)) \\\n",
    "        .withColumn(\"patient_responsibility\", F.col(\"gross_amount\") - F.col(\"insurance_covered\") + F.col(\"insurance_copay\")) \\\n",
    "        .withColumn(\"net_amount\", F.col(\"gross_amount\"))\n",
    "\n",
    "fact_table = fact_table \\\n",
    "    .withColumn(\"cost_amount\", F.col(\"quantity\") * F.col(\"unit_cost\")) \\\n",
    "    .withColumn(\"profit_amount\", F.col(\"net_amount\") - F.col(\"cost_amount\"))\n",
    "\n",
    "# Round monetary columns\n",
    "money_cols = [c for c in fact_table.columns if \"amount\" in c or \"price\" in c or \"cost\" in c]\n",
    "for col in money_cols:\n",
    "    fact_table = fact_table.withColumn(col, F.round(F.col(col), 2))\n",
    "\n",
    "print(f\"‚úÖ Fact table generated: {fact_table.count():,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "454d5a35-c8fd-4886-a19f-8e6c101e3b0c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-15T22:36:40.4774322Z",
       "execution_start_time": "2025-11-15T22:36:08.7546261Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "faa14e54-bd24-4e4e-80d3-02d1a07244bf",
       "queued_time": "2025-11-15T22:36:08.7533657Z",
       "session_id": "e3fa5b02-20b6-4b8f-a663-589c44bbfbe0",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 11,
       "statement_ids": [
        11
       ]
      },
      "text/plain": [
       "StatementMeta(, e3fa5b02-20b6-4b8f-a663-589c44bbfbe0, 11, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è  Dropping existing demo tables...\n",
      "======================================================================\n",
      "\n",
      "   Dropped table: demo_dim_customer\n",
      "   Dropped table: demo_dim_date\n",
      "   Dropped table: demo_dim_employee\n",
      "   Dropped table: demo_dim_location\n",
      "   Dropped table: demo_dim_product\n",
      "   Dropped table: demo_fact_orders\n",
      "   Dropped table: demo_fact_visits\n",
      "\n",
      "‚úÖ Dropped 7 objects\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DROP EXISTING TABLES (Clean Slate)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üóëÔ∏è  Dropping existing demo tables...\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Get all existing tables\n",
    "tables = spark.sql(\"SHOW TABLES\").select(\"tableName\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# Drop all demo tables and materialized views\n",
    "tables_to_drop = [t for t in tables if t.startswith(\"demo_\") or t.startswith(\"mv_\")]\n",
    "\n",
    "if tables_to_drop:\n",
    "    for table in tables_to_drop:\n",
    "        try:\n",
    "            # Check if it's a materialized view or regular table\n",
    "            if table.startswith(\"mv_\"):\n",
    "                spark.sql(f\"DROP MATERIALIZED VIEW IF EXISTS {table}\")\n",
    "                print(f\"   Dropped MV: {table}\")\n",
    "            else:\n",
    "                spark.sql(f\"DROP TABLE IF EXISTS {table}\")\n",
    "                print(f\"   Dropped table: {table}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Couldn't drop {table}: {str(e)}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Dropped {len(tables_to_drop)} objects\")\n",
    "else:\n",
    "    print(\"   No existing tables found\")\n",
    "\n",
    "print(\"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca64031-4c4e-48f0-9bb6-1ba681888cd6",
   "metadata": {},
   "source": [
    "## üíæ Step 8: Write to Lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a59fc493-fba3-4e53-80b9-2cf00449f98d",
   "metadata": {
    "advisor": {
     "adviceMetadata": "{\"artifactId\":\"5562ee49-3d5f-4970-b4b0-971f5687c954\",\"activityId\":\"e3fa5b02-20b6-4b8f-a663-589c44bbfbe0\",\"applicationId\":\"application_1763245202533_0001\",\"jobGroupId\":\"12\",\"advices\":{\"info\":1}}"
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-15T22:37:32.710899Z",
       "execution_start_time": "2025-11-15T22:36:49.6530312Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "56e4b25c-1c9b-4c4b-aade-0bed7a2abd22",
       "queued_time": "2025-11-15T22:36:49.6518544Z",
       "session_id": "e3fa5b02-20b6-4b8f-a663-589c44bbfbe0",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 12,
       "statement_ids": [
        12
       ]
      },
      "text/plain": [
       "StatementMeta(, e3fa5b02-20b6-4b8f-a663-589c44bbfbe0, 12, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üíæ Writing tables to Lakehouse...\n",
      "\n",
      "   Writing demo_dim_date...\n",
      "      ‚úÖ 365 rows\n",
      "\n",
      "   Writing demo_dim_product...\n",
      "      ‚úÖ 700 rows\n",
      "\n",
      "   Writing demo_dim_location...\n",
      "      ‚úÖ 100 rows\n",
      "\n",
      "   Writing demo_dim_customer...\n",
      "      ‚úÖ 800 rows\n",
      "\n",
      "   Writing demo_dim_employee...\n",
      "      ‚úÖ 150 rows\n",
      "\n",
      "   Writing demo_fact_orders...\n",
      "      ‚úÖ 25,000 rows\n",
      "\n",
      "======================================================================\n",
      "üéâ All tables written to Lakehouse!\n",
      "\n",
      "üìã Tables created:\n",
      "   - demo_dim_date\n",
      "   - demo_dim_product\n",
      "   - demo_dim_location\n",
      "   - demo_dim_customer\n",
      "   - demo_dim_employee\n",
      "   - demo_fact_orders\n"
     ]
    }
   ],
   "source": [
    "theme_clean = theme.lower().replace(\" \", \"_\")[:20]  # Limit length\n",
    "table_prefix = f\"{theme_clean}\"\n",
    "\n",
    "# Results in tables like:\n",
    "# sci_fi_formalwear_dim_product\n",
    "# sci_fi_formalwear_fact_sales\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üíæ Writing tables to Lakehouse...\\n\")\n",
    "\n",
    "table_prefix = \"demo\"\n",
    "tables_to_write = [\n",
    "    (dim_date, f\"{table_prefix}_dim_date\"),\n",
    "    (dim_product, f\"{table_prefix}_dim_product\"),\n",
    "    (dim_location, f\"{table_prefix}_dim_location\"),\n",
    "    (dim_customer, f\"{table_prefix}_dim_customer\"),\n",
    "    (dim_employee, f\"{table_prefix}_dim_employee\"),\n",
    "    (fact_table, f\"{table_prefix}_fact_{fact_name}\")\n",
    "]\n",
    "\n",
    "for df, table_name in tables_to_write:\n",
    "    print(f\"   Writing {table_name}...\")\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(table_name)\n",
    "    print(f\"      ‚úÖ {df.count():,} rows\\n\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üéâ All tables written to Lakehouse!\\n\")\n",
    "print(\"üìã Tables created:\")\n",
    "for _, table_name in tables_to_write:\n",
    "    print(f\"   - {table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "999010e9-e91e-4e46-af62-8f1e87367ce5",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-15T22:37:59.9999792Z",
       "execution_start_time": "2025-11-15T22:37:51.9376217Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "4f5e1445-3db7-47e9-83cc-03d5650417dc",
       "queued_time": "2025-11-15T22:37:51.9364476Z",
       "session_id": "e3fa5b02-20b6-4b8f-a663-589c44bbfbe0",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 13,
       "statement_ids": [
        13
       ]
      },
      "text/plain": [
       "StatementMeta(, e3fa5b02-20b6-4b8f-a663-589c44bbfbe0, 13, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Refreshing all demo tables...\n",
      "======================================================================\n",
      "\n",
      "   ‚úÖ Refreshed: demo_dim_customer\n",
      "   ‚úÖ Refreshed: demo_dim_date\n",
      "   ‚úÖ Refreshed: demo_dim_employee\n",
      "   ‚úÖ Refreshed: demo_dim_location\n",
      "   ‚úÖ Refreshed: demo_dim_product\n",
      "   ‚úÖ Refreshed: demo_fact_orders\n",
      "\n",
      "======================================================================\n",
      "‚úÖ Refreshed 6 tables - cache cleared!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# üîÑ REFRESH ALL TABLES (Dynamic - works for any business type)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üîÑ Refreshing all demo tables...\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Get all tables in the current database\n",
    "tables = spark.sql(\"SHOW TABLES\").select(\"tableName\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# Refresh all demo tables that exist\n",
    "refreshed = 0\n",
    "for table in tables:\n",
    "    if table.startswith(\"demo_\"):\n",
    "        try:\n",
    "            spark.sql(f\"REFRESH TABLE {table}\")\n",
    "            print(f\"   ‚úÖ Refreshed: {table}\")\n",
    "            refreshed += 1\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Couldn't refresh {table}: {str(e)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"‚úÖ Refreshed {refreshed} tables - cache cleared!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a930d2d2-4a47-4ca8-a3c6-b28442b72fc5",
   "metadata": {},
   "source": [
    "## üëÄ Step 9: Preview the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c291008-af25-4639-821e-d695ba5b8b88",
   "metadata": {
    "advisor": {
     "adviceMetadata": "{\"artifactId\":\"5562ee49-3d5f-4970-b4b0-971f5687c954\",\"activityId\":\"e3fa5b02-20b6-4b8f-a663-589c44bbfbe0\",\"applicationId\":\"application_1763245202533_0001\",\"jobGroupId\":\"14\",\"advices\":{\"info\":1}}"
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-15T22:38:07.3208239Z",
       "execution_start_time": "2025-11-15T22:38:06.4449297Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "069d0456-6843-48fc-ab91-143a598715cb",
       "queued_time": "2025-11-15T22:38:06.4437651Z",
       "session_id": "e3fa5b02-20b6-4b8f-a663-589c44bbfbe0",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 14,
       "statement_ids": [
        14
       ]
      },
      "text/plain": [
       "StatementMeta(, e3fa5b02-20b6-4b8f-a663-589c44bbfbe0, 14, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìä DATA PREVIEW\n",
      "\n",
      "üè∑Ô∏è  Themed Products:\n",
      "+-------------------------+-----------------+------------------+----------+\n",
      "|product_name             |category         |brand             |unit_price|\n",
      "+-------------------------+-----------------+------------------+----------+\n",
      "|Tasty Armadillo Appetizer|Stealthy Sides   |Grill Thrills     |447.62    |\n",
      "|Exotic Snake Sausage     |Roadkill Classics|Trackside Tastings|99.97     |\n",
      "|Exotic Fox Fritters      |Stealthy Sides   |Street Eats       |165.07    |\n",
      "|Hearty Toad Tacos        |Wild Wraps       |Furry Feasts      |117.19    |\n",
      "|Wild Gopher Gumbo        |Savory Soups     |Treaded Treats    |180.72    |\n",
      "|Savory Fox Fritters      |Sweet Road Trips |Street Eats       |39.36     |\n",
      "|Tasty Snake Sausage      |Wild Wraps       |Street Eats       |261.93    |\n",
      "|Wild Fox Fritters        |Savory Soups     |Furry Feasts      |38.47     |\n",
      "|Stealthy Beaver Bisque   |Hearty Hashes    |Treaded Treats    |401.18    |\n",
      "|Tasty Coyote Casserole   |Wild Wraps       |Street Eats       |120.69    |\n",
      "+-------------------------+-----------------+------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "üìç Themed Locations:\n",
      "+--------------------------------+-----------+---------+\n",
      "|location_name                   |city       |region   |\n",
      "+--------------------------------+-----------+---------+\n",
      "|Pavement Plateau Restaurant #1  |Chicago    |Southeast|\n",
      "|Roadkill Rest Stop Restaurant #2|Los Angeles|West     |\n",
      "|Asphalt Alley Restaurant #3     |Austin     |Northeast|\n",
      "|Pavement Plateau Restaurant #4  |Dallas     |Southwest|\n",
      "|Pavement Plateau Restaurant #5  |Houston    |Southwest|\n",
      "|Asphalt Alley Restaurant #6     |Chicago    |Midwest  |\n",
      "|Overpass Eatery Restaurant #7   |San Antonio|Southwest|\n",
      "|Overpass Eatery Restaurant #8   |San Diego  |Northeast|\n",
      "|Freeway Feast Restaurant #9     |Los Angeles|Midwest  |\n",
      "|Turnpike Treats Restaurant #10  |San Antonio|Southeast|\n",
      "+--------------------------------+-----------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "üë• Themed Customers:\n",
      "+----------+-----------+------------------------------+------------+\n",
      "|first_name|last_name  |email                         |loyalty_tier|\n",
      "+----------+-----------+------------------------------+------------+\n",
      "|Rex       |Grillmaster|rex.grillmaster@outlook.com   |Platinum    |\n",
      "|Milo      |Wild       |milo.wild@gmail.com           |Platinum    |\n",
      "|Rex       |Wild       |rex.wild@outlook.com          |NULL        |\n",
      "|Milo      |Grillmaster|milo.grillmaster@gmail.com    |Gold        |\n",
      "|Hunter    |Grillmaster|hunter.grillmaster@company.com|Bronze      |\n",
      "|Bruno     |Trackman   |bruno.trackman@outlook.com    |Silver      |\n",
      "|Milo      |Trackman   |milo.trackman@outlook.com     |NULL        |\n",
      "|Wren      |Feaster    |wren.feaster@gmail.com        |Gold        |\n",
      "|Rex       |Cruiser    |rex.cruiser@outlook.com       |Platinum    |\n",
      "|Jasper    |Hunt       |jasper.hunt@outlook.com       |Gold        |\n",
      "+----------+-----------+------------------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "üî• Fact Table (fact_orders):\n",
      "+-----------+--------------+------------+------------+------------+--------+-----------+--------+------------+----------+----------+-----------+----------+---------+------------+----------+----------+-----------+-------------+\n",
      "|product_key|transaction_id|location_key|customer_key|employee_key|date_key|hour_of_day|quantity|table_number|party_size|is_takeout|tip_percent|unit_price|unit_cost|gross_amount|tip_amount|net_amount|cost_amount|profit_amount|\n",
      "+-----------+--------------+------------+------------+------------+--------+-----------+--------+------------+----------+----------+-----------+----------+---------+------------+----------+----------+-----------+-------------+\n",
      "|50         |1             |54          |56          |60          |62      |17         |4       |14          |4         |0         |18         |392.1     |149.23   |1568.4      |282.31    |1850.71   |596.92     |1253.79      |\n",
      "|57         |2             |65          |69          |77          |81      |16         |5       |15          |5         |0         |19         |468.79    |31.9     |2343.95     |445.35    |2789.3    |159.5      |2629.8       |\n",
      "|64         |3             |76          |82          |94          |100     |15         |1       |16          |6         |1         |0          |460.1     |75.17    |460.1       |0.0       |460.1     |75.17      |384.93       |\n",
      "|71         |4             |87          |95          |111         |119     |14         |2       |17          |7         |0         |21         |409.64    |182.84   |819.28      |172.05    |991.33    |365.68     |625.65       |\n",
      "|78         |5             |98          |108         |128         |138     |13         |3       |18          |8         |0         |22         |45.06     |31.54    |135.18      |29.74     |164.92    |94.63      |70.29        |\n",
      "|85         |6             |9           |121         |145         |157     |12         |4       |19          |1         |0         |23         |412.13    |108.88   |1648.52     |379.16    |2027.68   |435.52     |1592.16      |\n",
      "|92         |7             |20          |134         |12          |176     |11         |5       |20          |2         |0         |24         |91.55     |64.09    |457.75      |109.86    |567.61    |320.42     |247.19       |\n",
      "|99         |8             |31          |147         |29          |195     |10         |1       |21          |3         |1         |0          |71.91     |8.31     |71.91       |0.0       |71.91     |8.31       |63.6         |\n",
      "|106        |9             |42          |160         |46          |214     |9          |2       |22          |4         |0         |16         |222.56    |155.79   |445.12      |71.22     |516.34    |311.58     |204.76       |\n",
      "|113        |10            |53          |173         |63          |233     |8          |3       |23          |5         |0         |17         |35.37     |24.76    |106.11      |18.04     |124.15    |74.28      |49.87        |\n",
      "+-----------+--------------+------------+------------+------------+--------+-----------+--------+------------+----------+----------+-----------+----------+---------+------------+----------+----------+-----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä DATA PREVIEW\\n\")\n",
    "\n",
    "print(\"üè∑Ô∏è  Themed Products:\")\n",
    "dim_product.select(\"product_name\", \"category\", \"brand\", \"unit_price\").show(10, truncate=False)\n",
    "\n",
    "print(\"\\nüìç Themed Locations:\")\n",
    "dim_location.select(\"location_name\", \"city\", \"region\").show(10, truncate=False)\n",
    "\n",
    "print(\"\\nüë• Themed Customers:\")\n",
    "dim_customer.select(\"first_name\", \"last_name\", \"email\", \"loyalty_tier\").show(10, truncate=False)\n",
    "\n",
    "print(f\"\\nüî• Fact Table (fact_{fact_name}):\")\n",
    "fact_table.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02bdcfb-8f04-46f0-819c-204af14bf41d",
   "metadata": {},
   "source": [
    "## üìà Step 10: Sample Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f318f10-8ead-43f2-8bff-86c020d1d572",
   "metadata": {
    "advisor": {
     "adviceMetadata": "{\"artifactId\":\"5562ee49-3d5f-4970-b4b0-971f5687c954\",\"activityId\":\"e3fa5b02-20b6-4b8f-a663-589c44bbfbe0\",\"applicationId\":\"application_1763245202533_0001\",\"jobGroupId\":\"15\",\"advices\":{\"info\":3}}"
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-15T22:39:02.6667346Z",
       "execution_start_time": "2025-11-15T22:38:59.0051376Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "8affab31-f0d6-4394-901b-c0994d947d45",
       "queued_time": "2025-11-15T22:38:59.0039574Z",
       "session_id": "e3fa5b02-20b6-4b8f-a663-589c44bbfbe0",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 15,
       "statement_ids": [
        15
       ]
      },
      "text/plain": [
       "StatementMeta(, e3fa5b02-20b6-4b8f-a663-589c44bbfbe0, 15, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìà SAMPLE ANALYTICS\n",
      "\n",
      "üí∞ Daily Revenue (Last 10 Days):\n",
      "+-------------------+------------------+------------------+------------+\n",
      "|date               |revenue           |profit            |transactions|\n",
      "+-------------------+------------------+------------------+------------+\n",
      "|2025-11-15 00:00:00|18249.260000000002|12896.94          |69          |\n",
      "|2025-11-14 00:00:00|47600.88999999999 |34137.32000000001 |68          |\n",
      "|2025-11-13 00:00:00|47638.25          |37295.770000000004|68          |\n",
      "|2025-11-12 00:00:00|92974.22          |62914.7           |69          |\n",
      "|2025-11-11 00:00:00|107056.21         |73078.96          |69          |\n",
      "|2025-11-10 00:00:00|17344.39          |12201.120000000003|68          |\n",
      "|2025-11-09 00:00:00|45027.26          |32067.63          |68          |\n",
      "|2025-11-08 00:00:00|49961.340000000004|37333.32          |69          |\n",
      "|2025-11-07 00:00:00|90739.40999999999 |62385.08          |69          |\n",
      "|2025-11-06 00:00:00|102048.59999999999|69817.13          |68          |\n",
      "+-------------------+------------------+------------------+------------+\n",
      "\n",
      "\n",
      "üèÜ Top 10 Products by Revenue:\n",
      "+-----------------------------+-----------------+-----------------+-----+\n",
      "|product_name                 |category         |revenue          |units|\n",
      "+-----------------------------+-----------------+-----------------+-----+\n",
      "|Stealthy Gopher Gumbo        |Sweet Road Trips |759639.9999999998|1250 |\n",
      "|Stealthy Armadillo Appetizer |Wild Wraps       |712859.9999999995|2000 |\n",
      "|Delicious Armadillo Appetizer|Savory Soups     |697652.5000000001|1250 |\n",
      "|Delicious Roadrunner Rolls   |Sweet Road Trips |697325.0000000003|1250 |\n",
      "|Delicious Squirrel Stew      |Sweet Road Trips |648459.9999999994|1250 |\n",
      "|Savory Armadillo Appetizer   |Roadkill Classics|612417.4999999998|1250 |\n",
      "|Hearty Porcupine Poppers     |Hearty Hashes    |612220.0000000001|1000 |\n",
      "|Wild Raccoon Ribs            |Savory Soups     |600162.5000000001|1250 |\n",
      "|Hearty Porcupine Poppers     |Grill Roadies    |597952.4999999998|1000 |\n",
      "|Hearty Toad Tacos            |Exotic Entrees   |580465.0000000001|1000 |\n",
      "+-----------------------------+-----------------+-----------------+-----+\n",
      "\n",
      "\n",
      "üè™ Top 10 Locations:\n",
      "+---------------------------------+------------+-----------------+------------+\n",
      "|location_name                    |city        |revenue          |transactions|\n",
      "+---------------------------------+------------+-----------------+------------+\n",
      "|Highway Haven Restaurant #40     |San Antonio |759639.9999999998|250         |\n",
      "|Intersection Inn Restaurant #95  |Houston     |697652.5000000001|250         |\n",
      "|Turnpike Treats Restaurant #65   |Houston     |697325.0000000003|250         |\n",
      "|Freeway Feast Restaurant #70     |Philadelphia|660377.5         |250         |\n",
      "|Overpass Eatery Restaurant #25   |Philadelphia|648459.9999999994|250         |\n",
      "|Highway Haven Restaurant #35     |Philadelphia|612417.4999999998|250         |\n",
      "|Roadkill Rest Stop Restaurant #89|Austin      |612220.0000000001|250         |\n",
      "|Pavement Plateau Restaurant #5   |Houston     |600162.5000000001|250         |\n",
      "|Freeway Feast Restaurant #59     |Austin      |597952.4999999998|250         |\n",
      "|Freeway Feast Restaurant #64     |Los Angeles |580465.0000000001|250         |\n",
      "+---------------------------------+------------+-----------------+------------+\n",
      "\n",
      "\n",
      "======================================================================\n",
      "‚úÖ Generation Complete!\n",
      "\n",
      "üéâ Your Roadkill Restaurant dataset is ready!\n",
      "   - 25,000 transactions generated\n",
      "   - 6 tables written to lakehouse\n",
      "   - Ready for analytics, ML, and BI!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìà SAMPLE ANALYTICS\\n\")\n",
    "\n",
    "print(\"üí∞ Daily Revenue (Last 10 Days):\")\n",
    "daily_revenue = fact_table.join(dim_date, \"date_key\") \\\n",
    "    .groupBy(\"date\") \\\n",
    "    .agg(\n",
    "        F.sum(\"net_amount\").alias(\"revenue\"),\n",
    "        F.sum(\"profit_amount\").alias(\"profit\"),\n",
    "        F.count(\"*\").alias(\"transactions\")\n",
    "    ).orderBy(F.desc(\"date\")).limit(10)\n",
    "daily_revenue.show(truncate=False)\n",
    "\n",
    "print(\"\\nüèÜ Top 10 Products by Revenue:\")\n",
    "top_products = fact_table.join(dim_product, \"product_key\") \\\n",
    "    .groupBy(\"product_name\", \"category\") \\\n",
    "    .agg(\n",
    "        F.sum(\"net_amount\").alias(\"revenue\"),\n",
    "        F.sum(\"quantity\").alias(\"units\")\n",
    "    ).orderBy(F.desc(\"revenue\")).limit(10)\n",
    "top_products.show(truncate=False)\n",
    "\n",
    "print(\"\\nüè™ Top 10 Locations:\")\n",
    "location_perf = fact_table.join(dim_location, \"location_key\") \\\n",
    "    .groupBy(\"location_name\", \"city\") \\\n",
    "    .agg(\n",
    "        F.sum(\"net_amount\").alias(\"revenue\"),\n",
    "        F.count(\"*\").alias(\"transactions\")\n",
    "    ).orderBy(F.desc(\"revenue\")).limit(10)\n",
    "location_perf.show(truncate=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Generation Complete!\")\n",
    "print(f\"\\nüéâ Your {theme} {business_type} dataset is ready!\")\n",
    "print(f\"   - {fact_row_count:,} transactions generated\")\n",
    "print(f\"   - 6 tables written to lakehouse\")\n",
    "print(f\"   - Ready for analytics, ML, and BI!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00565eb-f31b-412f-bf2d-b6cc075133e9",
   "metadata": {},
   "source": [
    "## üéì Next Steps\n",
    "\n",
    "### What to do with your data:\n",
    "\n",
    "**1. Build Dashboards**\n",
    "- Connect Power BI to your lakehouse\n",
    "- Create visualizations\n",
    "- Share with stakeholders\n",
    "\n",
    "**2. Run SQL Queries**\n",
    "```sql\n",
    "SELECT \n",
    "    p.category,\n",
    "    SUM(f.net_amount) as revenue,\n",
    "    COUNT(*) as transactions\n",
    "FROM demo_fact_orders f\n",
    "JOIN demo_dim_product p ON f.product_key = p.product_key\n",
    "GROUP BY p.category\n",
    "ORDER BY revenue DESC\n",
    "```\n",
    "\n",
    "**3. Train ML Models**\n",
    "- Revenue forecasting\n",
    "- Customer segmentation\n",
    "- Product recommendations\n",
    "\n",
    "**4. Generate More Datasets**\n",
    "- Try different themes!\n",
    "- Change business types\n",
    "- Increase scale to \"large\"\n",
    "\n",
    "---\n",
    "\n",
    "**Happy analyzing! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "bc1637b7-f40a-4bc9-8b8e-d941ba1c84ec",
    "default_lakehouse_name": "SQLSaturdayLake",
    "default_lakehouse_workspace_id": "26bb60a8-d9cb-4dfe-a4e4-02093143fde7",
    "known_lakehouses": [
     {
      "id": "bc1637b7-f40a-4bc9-8b8e-d941ba1c84ec"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
